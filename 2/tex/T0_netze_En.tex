\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{physics}
\usepackage{booktabs}
\usepackage{tcolorbox}
\usepackage{siunitx}
\usepackage[table,xcdraw]{xcolor}
\usepackage{hyperref}
\usepackage{array}
\usepackage{textgreek}

% Define common mathematical symbols for consistent usage
\newcommand{\xipar}{\ensuremath{\xi}}
\newcommand{\deltafield}{\ensuremath{\delta m}}
\newcommand{\partialop}{\ensuremath{\partial}}
\newcommand{\lambdah}{\ensuremath{\lambda_h}}
\newcommand{\betaT}{\ensuremath{\beta_T}}
\newcommand{\alphaEM}{\ensuremath{\alpha_{\text{EM}}}}
\newcommand{\rhofield}{\ensuremath{\rho}}
\newcommand{\mypi}{\ensuremath{\pi}}
\newcommand{\myphi}{\ensuremath{\phi}}
\newcommand{\myomega}{\ensuremath{\omega}}
\newcommand{\mytimes}{\ensuremath{\times}}
\newcommand{\myapprox}{\ensuremath{\approx}}
\newcommand{\myrightarrow}{\ensuremath{\rightarrow}}
\newcommand{\myRightarrow}{\ensuremath{\Rightarrow}}
\newcommand{\mypropto}{\ensuremath{\propto}}
\newcommand{\mysim}{\ensuremath{\sim}}
\newcommand{\mysqrt}{\ensuremath{\sqrt}}

\title{Network Representation and Dimensional Analysis in T0 Theory:\\
	\large Mathematical Framework, Dimensionality Effects, and Factorization Applications}
\author{Johann Pascher}
\date{\today}

\begin{document}
	
	\maketitle
	
	\begin{abstract}
		This analysis explores the network representation of the T0 model with particular focus on the dimensional aspects and their impact on factorization processes. The T0 model can be formulated as a multidimensional network where nodes represent spacetime points with associated time and energy fields. A critical finding is that different dimensionalities require distinct $\xi$ parameters, as the geometric scaling factor $G_d = 2^{d-1}/d$ varies with dimension $d$. In the context of factorization, this dimensional dependence creates a hierarchy of optimal $\xi_{\text{res}}$ values that scale inversely with problem size. Neural network implementations offer a promising approach to model the T0 framework, with dimension-adaptive architectures providing the flexibility needed to address both physical space representation and number space mapping. The fundamental difference between the 3+1 dimensional physical space and the potentially infinite-dimensional number space requires careful mathematical transformation, realized through spectral methods and dimension-specific network designs.
	\end{abstract}
	
	\tableofcontents
	\newpage
	
	\section{Introduction: Network Interpretation of the T0 Model}
	\label{sec:introduction}
	
	The T0 model, with its foundation in the universal geometric parameter $\xipar = \frac{4}{3} \mytimes 10^{-4}$, can be powerfully reformulated as a multidimensional network structure. This approach provides a mathematical framework that naturally accommodates both the physical space representation and the number space mapping that underlies factorization applications.
	
	\subsection{Network Formalism in the T0 Framework}
	\label{subsec:network_formalism}
	
	A T0 network can be mathematically defined as:
	
	\begin{equation}
		\mathcal{N} = (V, E, \{T(v), E(v)\}_{v \in V})
	\end{equation}
	
	Where:
	\begin{itemize}
		\item $V$ represents the set of vertices (nodes) in spacetime
		\item $E$ represents the set of edges (connections between nodes)
		\item $T(v)$ represents the time field value at node $v$
		\item $E(v)$ represents the energy field value at node $v$
	\end{itemize}
	
	The fundamental time-energy duality relation $T(v) \cdot E(v) = 1$ is maintained at each node.
	
	\subsection{Dimensional Aspects of Network Structure}
	\label{subsec:dimensional_aspects}
	
	The dimensionality of the network plays a crucial role in determining its properties:
	
	\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Dimensional Network Properties]
		In a $d$-dimensional network:
		\begin{itemize}
			\item Each node has up to $2d$ direct connections
			\item The geometric factor scales as $G_d = \frac{2^{d-1}}{d}$
			\item Field propagation follows $d$-dimensional wave equations
			\item Boundary conditions require $d$-dimensional specification
		\end{itemize}
	\end{tcolorbox}
	
	\section{Dimensionality and $\xi$ Parameter Variations}
	\label{sec:dimensionality_xi}
	
	\subsection{Geometric Factor Dependence on Dimension}
	\label{subsec:geometric_factor}
	
	One of the most significant discoveries in T0 theory is the dimensional dependence of the geometric factor:
	
	\begin{equation}
		G_d = \frac{2^{d-1}}{d}
	\end{equation}
	
	For our familiar 3-dimensional space, we obtain $G_3 = \frac{2^2}{3} = \frac{4}{3}$, which appears as the fundamental geometric constant in the T0 model.
	
	\begin{table}[htbp]
		\centering
		\begin{tabular}{ccc}
			\toprule
			\textbf{Dimension ($d$)} & \textbf{Geometric Factor ($G_d$)} & \textbf{Ratio to $G_3$} \\
			\midrule
			1 & 1/1 = 1 & 0.75 \\
			2 & 2/2 = 1 & 0.75 \\
			3 & 4/3 = 1.333... & 1.00 \\
			4 & 8/4 = 2 & 1.50 \\
			5 & 16/5 = 3.2 & 2.40 \\
			6 & 32/6 = 5.333... & 4.00 \\
			10 & 512/10 = 51.2 & 38.40 \\
			\bottomrule
		\end{tabular}
		\caption{Geometric factors for different dimensionalities}
		\label{tab:geometric_factors}
	\end{table}
	
	\subsection{Dimension-Dependent $\xi$ Parameters}
	\label{subsec:dimension_dependent_xi}
	
	A critical finding is that the $\xipar$ parameter must be adjusted for different dimensionalities:
	
	\begin{equation}
		\xipar_d = \frac{G_d}{G_3} \cdot \xipar_3 = \frac{d \cdot 2^{d-3}}{3} \cdot \frac{4}{3} \mytimes 10^{-4}
	\end{equation}
	
	This means that different dimensional contexts require different $\xipar$ values for consistent physical behavior.
	
	\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Critical Understanding: Multiple $\xi$ Parameters]
		It is a fundamental error to treat $\xipar$ as a single universal constant. Instead:
		
		\begin{itemize}
			\item $\xipar_{\text{geom}}$: The geometric parameter ($\frac{4}{3} \mytimes 10^{-4}$) in 3D space
			\item $\xipar_{\text{res}}$: The resonance parameter ($\approx 0.1$) for factorization
			\item $\xipar_d$: Dimension-specific parameters that scale with $G_d$
		\end{itemize}
		
		Each parameter serves a specific mathematical purpose and scales differently with dimension.
	\end{tcolorbox}
	
	\section{Factorization and Dimensional Effects}
	\label{sec:factorization_dimensional}
	
	\subsection{Factorization Requires Different $\xi$ Values}
	\label{subsec:factorization_xi}
	
	A profound insight from T0 theory is that factorization processes require different $\xipar$ values because they operate in effectively different dimensions:
	
	\begin{equation}
		\xipar_{\text{res}}(d) = \frac{\xipar_{\text{res}}(3)}{d-1} = \frac{0.1}{d-1}
	\end{equation}
	
	Where $d$ represents the effective dimensionality of the factorization problem.
	
	\subsection{Effective Dimensionality of Factorization}
	\label{subsec:effective_dimensionality}
	
	The effective dimensionality of a factorization problem scales with the size of the number being factored:
	
	\begin{equation}
		d_{\text{eff}}(n) \approx \log_2\left(\frac{n}{\xipar_{\text{res}}}\right)
	\end{equation}
	
	This leads to a profound realization: larger numbers exist in higher effective dimensions, which explains why factorization becomes exponentially harder as numbers grow.
	
	\begin{table}[htbp]
		\centering
		\begin{tabular}{ccc}
			\toprule
			\textbf{Number Range} & \textbf{Effective Dimension} & \textbf{Optimal $\xipar_{\text{res}}$} \\
			\midrule
			$10^2$ - $10^3$ & 3-4 & 0.05 - 0.1 \\
			$10^4$ - $10^6$ & 5-7 & 0.02 - 0.05 \\
			$10^8$ - $10^{12}$ & 8-12 & 0.01 - 0.02 \\
			$10^{15}$+ & 15+ & $<0.01$ \\
			\bottomrule
		\end{tabular}
		\caption{Effective dimensions and optimal resonance parameters}
		\label{tab:effective_dimensions}
	\end{table}
	
	\subsection{Mathematical Formulation of Dimensionality Effects}
	\label{subsec:mathematical_formulation}
	
	The optimal resonance parameter for factoring a number $n$ can be calculated as:
	
	\begin{equation}
		\xipar_{\text{res,opt}}(n) = \frac{0.1}{d_{\text{eff}}(n)-1} = \frac{0.1}{\log_2\left(\frac{n}{0.1}\right)-1}
	\end{equation}
	
	This relationship explains why different $\xipar$ values are required for different factorization problems, and provides a mathematical framework for determining the optimal parameter.
	
	\section{Number Space vs. Physical Space}
	\label{sec:number_physical_space}
	
	\subsection{Fundamental Dimensional Differences}
	\label{subsec:dimensional_differences}
	
	A key insight in T0 theory is the recognition that number space and physical space have fundamentally different dimensional structures:
	
	\begin{tcolorbox}[colback=green!5!white,colframe=green!75!black,title=Contrasting Dimensional Structures]
		\begin{itemize}
			\item \textbf{Physical space}: 3+1 dimensions (3 spatial + 1 temporal)
			\item \textbf{Number space}: Potentially infinite dimensions (each prime factor represents a dimension)
			\item \textbf{Effective dimension}: Determined by problem complexity, not fixed
		\end{itemize}
	\end{tcolorbox}
	
	\subsection{Mathematical Transformation Between Spaces}
	\label{subsec:mathematical_transformation}
	
	The transformation between number space and physical space requires sophisticated mathematical mapping:
	
	\begin{equation}
		\mathcal{T}: \mathbb{Z}_n \to \mathbb{R}^d, \quad \mathcal{T}(n) = \{E_i(x,t)\}
	\end{equation}
	
	This transformation maps numbers from the integer space $\mathbb{Z}_n$ to field configurations in $d$-dimensional real space $\mathbb{R}^d$.
	
	\subsection{Spectral Methods for Dimensional Mapping}
	\label{subsec:spectral_methods}
	
	Spectral methods provide an elegant approach to mapping between spaces:
	
	\begin{equation}
		\Psi_n(\omega, \xipar_{\text{res}}) = \sum_i A_i \times \frac{1}{\sqrt{4\pi\xipar_{\text{res}}}} \times \exp\left(-\frac{(\omega-\omega_i)^2}{4\xipar_{\text{res}}}\right)
	\end{equation}
	
	Where:
	\begin{itemize}
		\item $\Psi_n$ represents the spectral representation of number $n$
		\item $\omega_i$ represents the frequency associated with prime factor $p_i$
		\item $A_i$ represents the amplitude coefficient
		\item $\xipar_{\text{res}}$ controls the spectral resolution
	\end{itemize}
	
	\section{Neural Network Implementation of T0 Model}
	\label{sec:neural_network}
	
	\subsection{Optimal Network Architectures}
	\label{subsec:optimal_architectures}
	
	Neural networks offer a promising approach to implementing the T0 model, with several architectures being particularly suitable:
	
	\begin{table}[htbp]
		\centering
		\begin{tabular}{lp{8cm}}
			\toprule
			\textbf{Architecture} & \textbf{Advantages for T0 Implementation} \\
			\midrule
			Graph Neural Networks & Natural representation of spacetime network structure with nodes and edges \\
			Convolutional Networks & Efficient processing of regular grid patterns in different dimensions \\
			Fourier Neural Operators & Handles spectral transformations required for number-field mapping \\
			Recurrent Networks & Models temporal evolution of field patterns \\
			Transformers & Captures long-range correlations in field values \\
			\bottomrule
		\end{tabular}
		\caption{Neural network architectures for T0 implementation}
		\label{tab:network_architectures}
	\end{table}
	
	\subsection{Dimension-Adaptive Networks}
	\label{subsec:dimension_adaptive}
	
	A key innovation for T0 implementation is dimension-adaptive networks:
	
	\begin{tcolorbox}[colback=yellow!5!white,colframe=orange!75!black,title=Dimension-Adaptive Network Design]
		Effective T0 networks should adapt their dimensionality based on:
		\begin{itemize}
			\item \textbf{Problem domain}: Physical (3+1D) vs. Number space (variable D)
			\item \textbf{Problem complexity}: Higher dimensions for larger factorization tasks
			\item \textbf{Resource constraints}: Dimensional optimization for computational efficiency
			\item \textbf{Accuracy requirements}: Higher dimensions for more precise results
		\end{itemize}
	\end{tcolorbox}
	
	\subsection{Mathematical Formulation of Neural T0 Networks}
	\label{subsec:mathematical_neural}
	
	For Graph Neural Networks, the T0 model can be implemented as:
	
	\begin{equation}
		h_v^{(l+1)} = \sigma\left(W^{(l)} \cdot h_v^{(l)} + \sum_{u \in \mathcal{N}(v)} \alpha_{vu} \cdot M^{(l)} \cdot h_u^{(l)}\right)
	\end{equation}
	
	Where:
	\begin{itemize}
		\item $h_v^{(l)}$ is the state vector at node $v$ in layer $l$
		\item $\mathcal{N}(v)$ is the neighborhood of node $v$
		\item $W^{(l)}$ and $M^{(l)}$ are learnable weight matrices
		\item $\alpha_{vu}$ are attention coefficients
		\item $\sigma$ is a non-linear activation function
	\end{itemize}
	
	For spectral methods using Fourier Neural Operators:
	
	\begin{equation}
		(\mathcal{K}\phi)(x) = \int_{\Omega} \kappa(x,y) \phi(y) dy \approx \mathcal{F}^{-1}(R \cdot \mathcal{F}(\phi))
	\end{equation}
	
	Where $\mathcal{F}$ is the Fourier transform, $R$ is a learnable filter, and $\phi$ is the field configuration.
	
	\section{Dimensional Hierarchy and Scale Relations}
	\label{sec:dimensional_hierarchy}
	
	\subsection{Dimensional Scale Separation}
	\label{subsec:scale_separation}
	
	The T0 model reveals a natural dimensional hierarchy:
	
	\begin{equation}
		\frac{\xipar_{\text{res}}(d)}{\xipar_{\text{geom}}(d)} = \frac{d-1}{d \cdot 2^{d-3}} \cdot \frac{3 \cdot 10^1}{4 \cdot 10^{-4}} \approx \frac{d-1}{d \cdot 2^{d-3}} \cdot 7.5 \cdot 10^4
	\end{equation}
	
	This relationship demonstrates how the resonance and geometric parameters scale differently with dimension, creating a natural separation of scales.
	
	\subsection{Mathematical Relation to Zahlenraum}
	\label{subsec:zahlenraum_relation}
	
	The number space (Zahlenraum) has a fundamentally different dimensional structure than physical space:
	
	\begin{equation}
		\dim(\mathbb{Z}_n) = \infty \quad \text{(infinite for prime distribution)}
	\end{equation}
	
	This infinite-dimensional structure must be projected onto finite-dimensional networks, with the effective dimension:
	
	\begin{equation}
		d_{\text{effective}} = \log_2\left(\frac{n}{\xipar_{\text{res}}}\right)
	\end{equation}
	
	\subsection{Information Mapping Between Dimensional Spaces}
	\label{subsec:information_mapping}
	
	The information mapping between number space and physical space can be quantified by:
	
	\begin{equation}
		\mathcal{I}(n, d) = \int \Psi_n(\omega, \xipar_{\text{res}}) \cdot \Phi_d(\omega, \xipar_{\text{geom}}) \, d\omega
	\end{equation}
	
	Where $\Psi_n$ is the spectral representation of number $n$ and $\Phi_d$ is the $d$-dimensional field configuration.
	
	\section{Hybrid Network Models for T0 Implementation}
	\label{sec:hybrid_models}
	
	\subsection{Dual-Space Network Architecture}
	\label{subsec:dual_space}
	
	An optimal T0 implementation requires a hybrid network that addresses both physical and number spaces:
	
	\begin{equation}
		\mathcal{N}_{\text{hybrid}} = \mathcal{N}_{\text{phys}} \oplus \mathcal{N}_{\text{info}}
	\end{equation}
	
	Where $\mathcal{N}_{\text{phys}}$ is a 3+1D network for physical space and $\mathcal{N}_{\text{info}}$ is a variable-dimension network for information space.
	
	\subsection{Implementation Strategy}
	\label{subsec:implementation_strategy}
	
	\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Optimal T0 Network Implementation Strategy]
		\begin{enumerate}
			\item \textbf{Base layer}: 3D Graph Neural Network with physical time as fourth dimension
			\item \textbf{Field layer}: Node features encoding $E_{\text{field}}$ and $T_{\text{field}}$ values
			\item \textbf{Spectral layer}: Fourier transformations for mapping between spaces
			\item \textbf{Dimension adapter}: Dynamically adjusts network dimensionality based on problem complexity
			\item \textbf{Resonance detector}: Implements variable $\xipar_{\text{res}}$ based on number size
		\end{enumerate}
	\end{tcolorbox}
	
	\subsection{Neural Network Training Approach}
	\label{subsec:training_approach}
	
	Training a T0 neural network requires a multi-stage approach:
	
	\begin{enumerate}
		\item \textbf{Physical constraint learning}: Train the network to respect $T \cdot E = 1$ at every node
		\item \textbf{Wave equation dynamics}: Train to solve $\partial^2 \deltafield = 0$ in different dimensions
		\item \textbf{Dimensional transfer}: Train mapping between different dimensional spaces
		\item \textbf{Factorization tasks}: Fine-tune on specific factorization problems with appropriate $\xipar_{\text{res}}$
	\end{enumerate}
	
	\section{Practical Applications and Experimental Verification}
	\label{sec:practical_applications}
	
	\subsection{Factorization Experiments}
	\label{subsec:factorization_experiments}
	
	The dimensional theory of T0 networks leads to testable predictions for factorization:
	
	\begin{table}[htbp]
		\centering
		\begin{tabular}{ccc}
			\toprule
			\textbf{Number Size} & \textbf{Predicted Optimal $\xipar_{\text{res}}$} & \textbf{Predicted Success Rate} \\
			\midrule
			$10^3$ & 0.05 & 95\% \\
			$10^6$ & 0.025 & 80\% \\
			$10^9$ & 0.015 & 65\% \\
			$10^{12}$ & 0.01 & 50\% \\
			\bottomrule
		\end{tabular}
		\caption{Factorization predictions from dimensional T0 theory}
		\label{tab:factorization_predictions}
	\end{table}
	
	\subsection{Verification Methods}
	\label{subsec:verification_methods}
	
	The dimensional aspects of the T0 model can be verified through:
	
	\begin{itemize}
		\item \textbf{Dimension scaling tests}: Verify how performance scales with network dimension
		\item \textbf{$\xipar$ optimization}: Confirm optimal $\xipar_{\text{res}}$ values match theoretical predictions
		\item \textbf{Computational complexity}: Measure how factorization difficulty scales with number size
		\item \textbf{Spectral analysis}: Validate spectral patterns for different number factorizations
	\end{itemize}
	
	\subsection{Hardware Implementation Considerations}
	\label{subsec:hardware_implementation}
	
	T0 networks can be implemented on various hardware platforms:
	
	\begin{table}[htbp]
		\centering
		\begin{tabular}{lp{8cm}}
			\toprule
			\textbf{Hardware Platform} & \textbf{Dimensional Implementation Approach} \\
			\midrule
			GPU Arrays & Parallel processing of multiple dimensions with tensor cores \\
			Quantum Processors & Natural implementation of superposition across dimensions \\
			Neuromorphic Chips & Dimension-specific neural circuits with adaptive connectivity \\
			FPGA Systems & Reconfigurable architecture for variable dimensional processing \\
			\bottomrule
		\end{tabular}
		\caption{Hardware implementation approaches}
		\label{tab:hardware_approaches}
	\end{table}
	
	\section{Theoretical Implications and Future Directions}
	\label{sec:theoretical_implications}
	
	\subsection{Unified Mathematical Framework}
	\label{subsec:unified_framework}
	
	The dimensional analysis of T0 networks reveals a unified mathematical framework:
	
	\begin{tcolorbox}[colback=green!5!white,colframe=green!75!black,title=Unified T0 Mathematical Framework]
		\begin{equation}
			\boxed{\text{All reality} = \text{Universal field } \deltafield(x,t) \text{ dancing in } G_d\text{-characterized }d\text{-dimensional spacetime}}
		\end{equation}
		
		With $G_d = 2^{d-1}/d$ providing the geometric foundation across all dimensions.
	\end{tcolorbox}
	
	\subsection{Future Research Directions}
	\label{subsec:future_research}
	
	This analysis suggests several promising research directions:
	
	\begin{enumerate}
		\item \textbf{Dimension-optimal networks}: Develop neural architectures that automatically determine optimal dimensionality
		\item \textbf{Factorization algorithms}: Create algorithms that adjust $\xipar_{\text{res}}$ based on number size
		\item \textbf{Quantum T0 networks}: Explore quantum implementations that naturally handle higher dimensions
		\item \textbf{Physical-number space transformations}: Develop improved mappings between physical and number spaces
		\item \textbf{Adaptive dimensional scaling}: Implement networks that dynamically scale dimensions based on problem complexity
	\end{enumerate}
	
	\subsection{Philosophical Implications}
	\label{subsec:philosophical_implications}
	
	The dimensional analysis of T0 networks suggests profound philosophical implications:
	
	\begin{itemize}
		\item \textbf{Reality as dimensional projection}: Physical reality may be a 3+1D projection of higher-dimensional information spaces
		\item \textbf{Dimensionality as complexity measure}: The effective dimension of a system reflects its intrinsic complexity
		\item \textbf{Unified geometric foundation}: The factor $G_d = 2^{d-1}/d$ may represent a universal geometric principle across all dimensions
		\item \textbf{Number-space connection}: Mathematical structures (like numbers) and physical structures may be fundamentally connected through dimensional mapping
	\end{itemize}
	
	\section{Conclusion: The Dimensional Nature of T0 Networks}
	\label{sec:conclusion}
	
	\subsection{Summary of Key Findings}
	\label{subsec:key_findings}
	
	This analysis has revealed several profound insights:
	
	\begin{enumerate}
		\item Different $\xipar$ parameters are required for different dimensionalities, with $\xipar_d$ scaling with $G_d = 2^{d-1}/d$
		\item Factorization problems require different $\xipar_{\text{res}}$ values because they operate in effectively different dimensions
		\item The effective dimensionality of a factorization problem scales logarithmically with the number size
		\item Neural network implementations must adapt their dimensionality based on problem domain and complexity
		\item The number space and physical space have fundamentally different dimensional structures requiring sophisticated mapping
	\end{enumerate}
	
	\subsection{The Power of Dimensional Understanding}
	\label{subsec:dimensional_understanding}
	
	Understanding the dimensional aspects of T0 networks provides powerful insights:
	
	\begin{tcolorbox}[colback=yellow!5!white,colframe=orange!75!black,title=Key Dimensional Insights]
		\begin{itemize}
			\item The challenge of factorization is fundamentally a dimensional problem
			\item Large numbers exist in higher effective dimensions than small numbers
			\item Different $\xipar$ values represent geometric factors in different dimensions
			\item Neural networks must adapt their dimensionality to the problem context
			\item The physical 3+1D space is just one specific case of the general $d$-dimensional T0 framework
		\end{itemize}
	\end{tcolorbox}
	
	\subsection{Final Synthesis}
	\label{subsec:final_synthesis}
	
	The dimensional analysis of T0 networks reveals a profound unity between mathematics, physics, and computation:
	
	\begin{equation}
		\boxed{\text{T0 Unification} = \text{Geometry} (G_d) + \text{Field Dynamics} (\partial^2\deltafield = 0) + \text{Dimensional Adaptation} (d_{\text{eff}})}
	\end{equation}
	
	This unified framework provides a powerful approach to understanding both physical reality and mathematical structures like factorization, all within a single elegant geometric framework characterized by the dimension-dependent factor $G_d = 2^{d-1}/d$.
	
	\begin{thebibliography}{9}
		
		\bibitem{pascher_xi_parameter_2025}
		Pascher, J. (2025). \textit{The $\xi$ Parameter and Particle Differentiation in T0 Theory}.
		
	\end{thebibliography}
	
\end{document}