% Chapter 12
% Auto-reconstructed from FFGFT_Xi_Narrative_Master_De_print.pdf
% RAW source: 2\narrative\xi_de_chapters_raw\Kapitel_12_Xi_De_raw.txt
% English translation

\chapter{Natural Units and Constants Reinterpreted}


In the preceding chapters, several scales have already been introduced that follow directly from time-mass duality and the parameter $\xi$: the energy scale $E_0$ in the MeV range, a minimal length scale $L_0 = \xi L_P$ in the sub-Planck range, and a vacuum length scale $L_\xi$ on the order of 100 µm.

This chapter explains why the use of natural units is the key to understanding these relationships – and why some familiar units (such as the coulomb) must be reinterpreted within this framework.

\section{Why Natural Units?}

The International System of Units (SI) is optimized for practical measurability and technical applications: meters, kilograms, seconds, amperes, and kelvin are historically evolved quantities oriented toward laboratory standards. For the structure of fundamental laws, however, they are often inconvenient because they "hide" central constants like $c$, $\hbar$, and the elementary charge $e$ within the units themselves.

Natural units pursue a different approach:
\begin{itemize}
	\item Fundamental constants such as $c$ and $\hbar$ are set equal to one.
	\item Lengths, times, and energies are directly converted into each other.
	\item Many seemingly complicated constants disappear from the formulas, making room for dimensionless ratios.
\end{itemize}

It is important to note: $c = 1$ does not mean that "energy and mass are always equal", but that in the rest frame of a particle $E = m$ abbreviates the familiar relation $E = mc^2$; dynamically, the full equation $E^2 = p^2 + m^2$ remains valid. The same applies mutatis mutandis to $\hbar = 1$ and (with suitable normalization) $\alpha \approx 1/137$: Setting them to one is a notation, not new physics – the logical step back to the physical quantities must always be explicitly considered and ultimately performed through dimensional checking.

In the context of time-mass duality, quantities such as $E_0$, $L_0$, and $L_\xi$ serve as natural scales of a fractally organized space; however, their full significance only becomes apparent when, after a calculation in natural units, one carefully converts back to the familiar SI units and compares the scales with measurement data.

\section{The Dual View of $\alpha$, $c$, and $\hbar$}

The fine-structure constant $\alpha$ is the classic example of how strongly the choice of units influences understanding. In SI notation, a common form is
\begin{equation}
	\alpha = \frac{e^2}{4\pi\varepsilon_0 \hbar c},
	\label{eq:alpha_SI}
\end{equation}
where $e$ is the elementary charge, $\varepsilon_0$ the electric constant, $\hbar$ the reduced Planck constant, and $c$ the speed of light.

This representation suggests four independent quantities. In natural units with $c = \hbar = 1$ and an appropriate normalization of the electromagnetic field, however, the relation reduces to
\begin{equation}
	\alpha = \frac{e^2}{4\pi},
	\label{eq:alpha_natural}
\end{equation}
so that $\alpha$ directly describes the square of a dimensionless coupling.

Time-mass duality adds a second, complementary view:
\begin{equation}
	\alpha = \xi\left(\frac{E_0}{1\ \text{MeV}}\right)^2.
	\label{eq:alpha_xi}
\end{equation}

The fractal structure inherent in this relation only becomes visible when $\alpha$ is translated back from this form into concrete units and numerical values. Thus, $\alpha$ appears simultaneously
\begin{itemize}
	\item as a ratio of charge to light and action quanta ($e^2/4\pi\hbar c$) and
	\item as a geometrically organized number from $\xi$ and the fractally emergent scale $E_0$.
\end{itemize}

This dual view becomes especially transparent when choosing units such that $c$ and $\hbar$ appear not as "factors at the margin", but as structure-givers of the scales.

\section{The Coulomb Reinterpreted}

In the SI system, the unit of charge, the coulomb, is a historically defined quantity fixed via the ampere and ultimately via macroscopic currents. From an FFGFT perspective, this is unsatisfactory because the fundamental processes in the electromagnetic sector are determined not by macroscopic conductor currents but by quantized charge carriers and their couplings to the field.

Natural units offer a clearer view here:
\begin{itemize}
	\item The electromagnetic field is normalized so that $e$ becomes a dimensionless quantity.
	\item The effective unit of charge is determined by $\alpha$ and the choice of $c$ and $\hbar$.
	\item Instead of the "coulomb" as a separate base unit, a geometry emerges in which charge is a measure of how strongly a field couples to the fractal time-mass structure.
\end{itemize}

In this picture, $e$ is not a freely adjustable parameter but fixed by $\alpha$ and the scales determined by $\xi$. The SI coulomb can then be interpreted as a derived quantity that is practical for macroscopic currents but obscures the underlying geometry.

\section{Newly Defined Units for a Clear Geometry}

Time-mass duality suggests deliberately choosing units so that geometric relationships become visible:
\begin{itemize}
	\item Base units are oriented toward natural scales such as $E_0$, $L_0$, and $L_\xi$.
	\item $c$ and $\hbar$ are used as conversion factors between time, length, and energy, not as "additional numbers".
	\item Electromagnetic quantities are normalized so that $\alpha$ appears directly as a quadratic coupling.
\end{itemize}

Practically, this means for example:
\begin{itemize}
	\item An energy unit in the MeV range (close to $E_0$) makes the role of the lepton scale visible.
	\item A length unit on the order of $L_\xi$ highlights the connection between CMB and the Casimir effect.
	\item Time intervals are systematically linked to local mass densities, as suggested by time-mass duality.
\end{itemize}

Such decisions are not merely matters of taste; they determine whether patterns in the data are recognized as a coherent whole or disappear behind a multitude of conversion factors.

\section{Natural Units as a Thinking Tool}

Natural units force one to treat constants like $c$, $\hbar$, and $e$ not as "ornamental script" in formulas but as expressions of concrete geometric structures. In FFGFT, these structures are organized by $\xi$, the fractal dimension $D_f$, and the scales derived from them.

Those who calculate in natural units see more quickly where genuinely new physics lies:
\begin{itemize}
	\item Unit conversions disappear, making room for dimensionless quantities.
	\item Differences between models can be clearly located in changed couplings or scales.
	\item The connection between the micro- and macro-worlds (from lepton masses to Hubble scales) becomes recognizable as a relationship of few numbers and scales.
\end{itemize}

In this sense, natural units are not only a technical aid but a thinking tool: They make the geometric core of time-mass duality visible and show how $\alpha$, $c$, $\hbar$, and $e$ can be understood as different projections of the same fractal structure.

\section{What Is Lost When Setting $c$, $\hbar$, $G$, and $\alpha$ to One}

In practice, it is tempting to simply "normalize away" all constants. For the Xi narrative, however, it is important which aspects of the fractal structure become invisible in the process:
\begin{itemize}
	\item Setting $c = 1$ removes the explicit speed of light from the equations. The Lorentz structure and the separation of space and time remain, but the contrast between non-relativistic and relativistic scales becomes less visible.
	\item Setting $\hbar = 1$ loses the explicit scale at which processes become "quantum-like". The limit $\hbar \to 0$ and the comparison "small compared to $\hbar$" versus "large compared to $\hbar$" disappear as distinct sequences from the formulas.
	\item Setting $G = 1$ makes the coupling of spacetime curvature to energy-momentum dimensionless. This loses the direct reference between local densities, curvature radii, and the fractally organized scales $L_0$ and $L_\xi$ within a unit choice.
	\item Finally, attempting to set $\alpha$ "to one" is not merely choosing a unit but making a physical assumption about the strength of the electromagnetic coupling. In FFGFT, this would precisely lose the information that $\alpha$ can be read as a fractal function of scale – the finely structured interactions would be compressed into a single smooth number.
\end{itemize}

Historically, this was also the starting point of the FFGFT perspective presented here: Only when $\alpha = 1$ was consciously and deliberately set in intermediate calculations did the underlying three-dimensional geometric relationships clearly emerge. Precisely the comparison between this "smoothed" picture and the later reconstructed fractal scale dependence made visible the additional structure contained in a variable, geometrically organized fine-structure constant.

For concrete calculations, this means: In a first step, one can work with $\alpha = 1$ in a smoothed, three-dimensional geometry, provided that in every formula it is clearly noted with which power $\alpha$ truly enters (e.g., $\sigma \propto \alpha^2$, energy levels $\propto \alpha^2$, lifetimes $\propto \alpha^{-1}$, etc.). In this step, all computational steps become transparent, but the fractal scale dependence of $\alpha$ is consciously "hidden". In a second, equally systematic step, the corresponding $\alpha$ factors – with the correct power and at the appropriate scale – are explicitly restored during reconversion, thereby reconstructing the fractal coupling structure. Only here does one decide whether $\alpha$ is read as constant or as a running, fractally organized quantity.

In the sense of the Xi narrative, one can say: $c$, $\hbar$, and $G$ can be hidden as conversion factors in the background without fundamentally destroying the fractal structure; they become harder to see but remain conceptually present. If we were also to consistently set $\alpha$ to one, however, the model would be reduced to an almost purely three-dimensional, smooth geometry – precisely that fine fractal scale structure of couplings that the Xi book elaborates would be lost in the formalism, even though it continues to act in the data.

\section{Calculation Examples: Consciously Switching $\alpha$ Off and On Again}

To make this two-stage approach tangible, it is worthwhile to look at concrete example calculations:
\begin{enumerate}
	\item \textbf{Geometric step with $\alpha = 1$:} First, all relevant observables are rewritten so that their dependence on $\alpha$ is explicit, e.g., $\sigma(E) = C(E) \alpha^2$ for a cross section, an energy shift $\Delta E \propto \alpha^2$, or a lifetime $\tau \propto \alpha^{-1}$. In this first step, one sets $\alpha = 1$ and examines only the geometric prefactors $C(E)$ and their dependence on scales like $E_0$, $L_0$, and $L_\xi$.
	\item \textbf{Reconstruction step with physical $\alpha$:} In a second pass, the full $\alpha$ factors are restored with the correct power and at the appropriate scale and evaluated with their physical value. Here, the fractal running of $\alpha$ with energy or length and the interpretation of the data as a projection of a deeper fractal geometry enter.
\end{enumerate}

In everyday work, a theorist can therefore indeed "forget" that $\alpha$ depends on scale in the first pass, to initially uncover only the pure three-dimensional geometry – provided the bookkeeping of the powers of $\alpha$ is done cleanly. What is specific to the FFGFT/Xi perspective is the emphasis that the second step is not optional: Precisely in the controlled re-introduction of $\alpha(E)$ lies the key to how a deterministic, fractal field theory can reproduce seemingly probabilistic data and yet leave room for effective freedom, emergent decisions, and conscious agency on macroscopic scales.


