\documentclass[12pt,a4paper]{article}
% === Include T0 Standard Preamble ===
\input{../../../T0_preamble_shared_En} % Assuming an English version exists; otherwise, adjust accordingly
% === Ensure TOC is displayed ===
\setcounter{tocdepth}{3}  % Show sections, subsections, and subsubsections
\title{\textbf{The Circularity in the Debate on Fundamental Constants}\\
	\large Historical Assignment, Conventions, and Resolution through Geometric Reduction}
\author{Johann Pascher}
\date{December 21, 2025}

\begin{document}
	\maketitle
	
	\begin{abstract}
		This document illuminates the debate on fundamental physical constants: Why the question of what counts as a constant, convention, or measurement data often runs in circles. The assignment has grown historically, is framework-dependent, and strongly shaped by conventions. It explains how this circularity arises and how it can be resolved through modern approaches: Matsas et al. (2024) show that in relativistic spacetimes, operationally, a single time unit suffices; the T0 theory reduces everything to a geometric parameter $\xi = \frac{4}{3} \times 10^{-4}$, derived from the tetrahedral packing structure of spacetime. The focus is on a clear, factual analysis showing that only \emph{one} dimensionless parameter is fundamental -- all other constants are conventions, measurement data, or derived ratios. The analysis is secured up to the sub-Planck limit $L_0 = \xi \, \ell_P \approx 5.39 \times 10^{-39}\,\text{m}$.
	\end{abstract}

\tableofcontents
\newpage	
	\section{Introduction: The Question of Fundamentality}
	The debate ``How many fundamental constants does physics really need?'' and ``What is fundamental, what is convention, and what is measurement data?'' is a central topic in the philosophy of physics and metrology. It often appears circular because the answer depends on the chosen theoretical and metrological framework. The historical development of physics has strongly shaped the assignment --- an observation that is accurate but does not capture the entire complexity.
	
	\section{The Circularity of the Debate}
	
	\subsection{Preliminary Note: The Central Thesis}
	After complete analysis, only \textbf{one single dimensionless parameter} remains fundamental: $\xi = \frac{4}{3} \times 10^{-4}$. All other constants ($c$, $\hbar$, $G$, $\alpha$, mass ratios) are conventions, derived ratios, or still open measurement data.
	
	\subsection{Definitions and Criteria}
	A constant is considered \textbf{fundamental} if it:
	\begin{itemize}
		\item is independent of other quantities,
		\item cannot be further reduced,
		\item is universal and theoretically necessary.
	\end{itemize}
	Conventions are human choices (e.g., units), measurement data are empirical values.
	
	The problem: These criteria are not absolute but \textbf{framework-dependent}. Changing the framework changes the classification --- a circle.
	\begin{itemize}
		\item In non-relativistic physics: Three independent dimensions (time, length, mass) $\to$ three constants needed.
		\item In relativistic spacetime: Length derivable from time $\to$ one constant (e.g., time unit) suffices.
		\item In geometric approaches: Everything emerges from structure $\to$ zero or one parameter.
	\end{itemize}
	
	To decide whether, e.g., $c$ is fundamental, one already needs a framework --- circularity.
	
	\subsection{Examples of Circularity}
	\begin{enumerate}
		\item \textbf{Measurement vs. Definition}: The gravitational constant $G$ is measured, but using masses and lengths that in turn depend on $c$ and $\hbar$. In the SI reform of 2019, $c$, $\hbar$ were fixed (convention), $G$ remains measurable.
		\item \textbf{Dimensional vs. Dimensionless}: Dimensional constants (e.g., $c$) can be set to 1 by unit choice $\to$ convention. Dimensionless ones like $\alpha \approx 1/137$ seem ``truly'' fundamental --- until derived.
		\item \textbf{Operational vs. Ontological}: Operationally (measurement practice), one clock suffices (Matsas et al., 2024). Ontologically (what exists?), geometry might explain everything.
	\end{enumerate}
	
	\section{The Historical Assignment}
	The assignment is largely historically determined:
	\begin{itemize}
		\item Newton (1687): $G$ as empirical constant.
		\item 19th century: $c$ from electromagnetism.
		\item Planck (1899): Natural units with $c$, $\hbar$, $G$.
		\item SI system: Historical artifacts (e.g., kilogram prototype until 2019).
		\item Duff--Okun--Veneziano controversy (2000s): Arising from quantum field theory and string theory.
	\end{itemize}
	Physics developed stepwise (mechanics $\to$ electromagnetism $\to$ quantum $\to$ relativity), so constants act as ``bridges'' and appear fundamental --- a pragmatic, historical decision.
	
	\section{Resolution of the Circularity}
	Modern approaches break the circle:
	\begin{itemize}
		\item \textbf{Matsas et al. (2024)}: Shows framework-dependently that in relativistic spacetimes, operationally, one time unit suffices (three-clock experiment, Compton relation).
		\item \textbf{T0 Theory}: Reduces everything to a geometric parameter $\xi = \frac{4}{3} \times 10^{-4}$, derived from packing principles --- not historical/conventional, but structurally grounded.
	\end{itemize}
	These approaches make fundamentality less circular by reducing to deeper levels (spacetime structure, geometry).
	
	\subsection{The Mathematical Hierarchy of the T0 Theory}
	
	The T0 theory establishes an unambiguous derivation chain from the geometric parameter $\xi$. The order is crucial and based on the structure of the theory:
	
	\begin{enumerate}
		\item \textbf{Starting Point -- Geometry}: The tetrahedral packing deficit
		\[
		\xi = 1 - \frac{V_{\text{Tetradouble}}}{V_{\text{Sphere}}} = \frac{4}{3} \times 10^{-4}
		\]
		on the Planck scale is the only fundamental parameter (see document 009\_T0\_xi\_ursprung).
		
		\item \textbf{Fractal Dimension}: From $\xi$ follows the fractal dimension
		\[
		D_f = 3 - \xi \approx 2.9998667
		\]
		This is \emph{not freely choosable} -- there is only one single way to determine $D_f$ from the geometric structure. The justification is found in documents 008\_T0\_xi-und-e and 009\_T0\_xi\_ursprung.
		
		\item \textbf{Characteristic Energy Scale}: $E_0$ emerges from mass ratios, particularly the electron-muon ratio:
		\[
		E_0 = \frac{m_\mu}{m_e} \cdot \text{(geometric factor)} \approx 33.12
		\]
		Detailed derivations are found in document 006\_T0\_Teilchenmassen.
		
		\item \textbf{Fine-Structure Constant}: Derivable from $E_0$ and the fractal dimension $D_f$:
		\[
		\alpha = f(E_0, D_f) \approx \frac{1}{137.036}
		\]
		The explicit formula and justification is found in document 011\_T0\_Feinstruktur.
		
		\item \textbf{Planck Constant and Speed of Light}: Emerge from the time-mass duality
		\[
		\hbar = \frac{m_P \, c^2 \, t_P}{2\pi} \quad \text{and} \quad c = \frac{\ell_P}{t_P}
		\]
		where $t_P$ is the Planck time.
		
		\item \textbf{Gravitational Constant}: Follows from geometric definition
		\[
		G = \frac{\ell_P \, c^2}{m_P} = \frac{\ell_P^3}{t_P^2 \, m_P}
		\]
		
		\item \textbf{Elementary Charge}: Via the fine-structure constant
		\[
		e^2 = 4\pi \alpha \epsilon_0 \hbar c
		\]
		
		\item \textbf{Mass Ratios}: Systematically derivable from fractal hierarchy and $\xi$-couplings (see document 006\_T0\_Teilchenmassen).
	\end{enumerate}
	
	This hierarchy shows: Only $\xi$ is fundamental. The fractal dimension $D_f$ is uniquely determined (not freely choosable), $E_0$ follows from mass ratios, $\alpha$ from $E_0$ and $D_f$, and everything else follows mathematically or is convention in unit choice.
	
	\section{Why Ratio-Based Relations Do Not Need Units}
	Ratio-based relations --- such as dimensionless constants or ratios of physical quantities --- do not require units as long as no real applications with human-made units (e.g., SI units) are realized. The following explanation shows why this is the case.
	
	\subsection{Basic Principle: Dimensionlessness}
	Ratios are by definition \textbf{dimensionless}: They arise from dividing similar quantities, canceling all physical dimensions.
	Examples:
	\begin{itemize}
		\item Fine-structure constant $\alpha = \frac{e^2}{4\pi \epsilon_0 \hbar c} \approx \frac{1}{137.036}$:
		The dimensions of charge, Planck's constant, speed of light, and permittivity fully cancel $\to$ pure number.
		\item Proton-electron mass ratio $m_p / m_e \approx 1836.15$:
		Both quantities have dimension [mass] $\to$ the ratio is dimensionless.
		\item Koide formula for lepton masses:
		$\frac{m_e + m_\mu + m_\tau}{(\sqrt{m_e} + \sqrt{m_\mu} + \sqrt{m_\tau})^2} = \frac{2}{3} + \mathcal{O}(10^{-5})$ --- again a pure number.
	\end{itemize}
	Such ratios are invariant to the choice of unit systems. Their numerical value remains the same, whether using SI, Planck, or natural units.
	
	\subsection{Pure Theory vs. Practical Application}
	In a purely theoretical description of nature --- as long as no concrete measurement or technical application with human-made standards is performed --- it is entirely sufficient to work exclusively with ratios and dimensionless quantities.
	\begin{itemize}
		\item All physical laws can be written in dimensionless form (Buckingham $\pi$-theorem).
		\item The entire dynamics of a system is determined by ratios of masses, charges, coupling constants, etc.
		\item Dimensional constants like $c$, $\hbar$, or $G$ serve in this context merely as conversion factors between different dimensions --- they are not substantively necessary.
	\end{itemize}
	Example: The equations of motion in general relativity or quantum field theory can be formulated so that only dimensionless parameters appear. The choice of a time unit or length unit is then pure convention.
	
	\subsection{The Transition to Realization with Human-Made Units}
	Units become relevant only when linking the theory to the real world:
	\begin{itemize}
		\item \textbf{Metrology}: To specify a length in meters, one needs an operationally defined standard (e.g., speed of light $c$ and second).
		\item \textbf{Technical Applications}: Building devices, communicating measured values, comparing with experiments require common, human-made units.
		\item \textbf{SI Reform 2019}: Here, dimensional constants ($c$, $\hbar$, $e$, $k_B$) were deliberately fixed to exact values to define units --- a clear indication that these constants serve as conventions.
	\end{itemize}
	Without this step of realization, all physical statements remain unit-free and depend only on ratios.
	
	\subsection{Conclusion of this Section}
	Ratio-based relations are the actual substance of physics: They describe the structure of nature independently of human conventions. Units and dimensional constants only arise when we perform measurements or communicate results. In a purely geometric or structural theory (like the T0 theory), one can therefore completely dispense with units and derive everything from a single dimensionless parameter $\xi$ --- units emerge only when applying to the measurable world.
	
	\section{Dimensional Quantities Can Be Converted to Dimensionless Ones}
	Dimensional constants or quantities can be converted to dimensionless quantities through appropriate redefinition of units if the new units exclusively reflect the underlying ratio. This shows that the apparent ``fundamentality'' of dimensional constants is often just a question of the chosen unit convention.
	
	\subsection{Basic Idea: Natural Unit Systems}
	By choosing a unit system in which certain physical constants receive the value 1, these constants are eliminated from the equations and lose their dimension.
	Classic examples:
	\begin{itemize}
		\item \textbf{Planck Units}: Here, $c = \hbar = G = k_B = 1$ are set.
		Length, time, mass, and temperature thereby receive the dimensions of Planck scales. All equations become dimensionless except for any remaining dimensionless parameters.
		\item \textbf{Natural Units in Particle Physics}: Often $c = \hbar = 1$.
		Energy, mass, momentum, and inverse length/time then have the same dimension. The speed of light $c$ and Planck's constant $\hbar$ disappear from the formulas.
		\item \textbf{Heaviside-Lorentz Units}: $\epsilon_0 = 1$, whereby the fine-structure constant $\alpha = e^2/(4\pi)$ and charges appear dimensionless.
	\end{itemize}
	In such systems, the formerly dimensional constants ($c$, $\hbar$, $G$, $\epsilon_0$) are no longer independent quantities --- they are fixed to 1 by unit choice.
	
	\subsection{General Principle}
	Any dimensional constant $K$ with dimension $[K] = [L]^a [T]^b [M]^c \dots$ can be eliminated by defining a new unit that carries exactly this dimension and uses $K$ as the reference value.
	Example:
	\begin{itemize}
		\item Instead of measuring $c = 299{,}792{,}458\,\text{m/s}$, define the meter so that $c \equiv 1$ (exactly what happened in the SI reform 1983/2019).
		Result: $c$ is no longer a measurable constant but a definitional convention without dimension in this system.
		\item Similarly, one could set $G = 1$ by introducing a ``Planck mass'' unit --- $G$ would then become dimensionless.
	\end{itemize}
	The result is always the same: The constant disappears from the physical laws and becomes a pure unit convention.
	
	\subsection{Consequence for the Fundamentality Debate}
	This clearly shows why dimensional constants are seen as less fundamental in the Duff--Okun--Veneziano controversy (Duff position):
	\begin{itemize}
		\item They can be eliminated by unit choice.
		\item Only the remaining \textbf{dimensionless} parameters (e.g., $\alpha$, mass ratios, Yukawa couplings) are invariant to unit changes.
		\item These dimensionless ratios are the actual free parameters of nature --- everything else is convention.
	\end{itemize}
	In the T0 theory, this thought is taken to its radical conclusion: Even the dimensionless constants like $\alpha$ or mass ratios are not considered free but derived from a single geometric parameter $\xi$. Thus, ultimately, any arbitrary unit choice is eliminated --- the structure of nature is completely described by a single dimensionless ratio.
	
	\subsection{Conclusion of this Section}
	Dimensional quantities are only apparently fundamental. Through redefinition of units that exactly reflect the relevant ratio, they can arbitrarily be converted into dimensionless conventions (value 1). The truly invariant and thus potentially fundamental quantities are exclusively the dimensionless ratios. Only when these are also reduced or explained (as in geometric approaches) does one approach a unit-independent description of physics.
	
	\section{The Equivalence of $\alpha$ and $\xi$ in the T0 Theory}
	From the perspective of the T0 theory, the fine-structure constant $\alpha$ --- traditionally viewed as one of the ``truly'' fundamental dimensionless constants --- is nothing but a ratio equivalent to the geometric parameter $\xi$. This shows that the question ``What is fundamental?'' ultimately depends on the chosen starting basis: $\xi$ and $\alpha$ are two equivalent descriptions of the same underlying fact.
	
	\subsection{The Bidirectional Derivation}
	In the T0 theory, there are multiple consistent and mathematically equivalent formulations:
	\begin{enumerate}
		\item \textbf{Start from $\xi$ (geometric perspective --- preferred in T0):}
		\[
		\xi = \frac{4}{3} \times 10^{-4}
		\]
		is the primary parameter describing the ratio between tetrahedral and spherical packing on the Planck scale. From this, $\alpha$ is derived:
		\[
		\alpha = \xi \cdot E_0^2 ,
		\]
		where $E_0 \approx e^{\kappa/2}$ is a harmonic energy scale ($\kappa = 7$). Numerically, this yields exactly the measured value $\alpha \approx 1/137.036$.
		
		Here, $\xi$ is fundamental (geometrically justified), $\alpha$ a derived ratio.
		
		\item \textbf{Start from $\alpha$ (electromagnetic perspective):}
		$\alpha \approx \frac{1}{137.036}$
		is taken as the starting point. From this, $\xi$ is calculated backward:
		\[
		\xi = \frac{\alpha}{E_0^2} .
		\]
		Since $E_0$ also follows from harmonic and geometric principles, one obtains exactly the same value $\xi = \frac{4}{3} \times 10^{-4}$.
		
		In this formulation, $\alpha$ appears fundamental, while $\xi$ becomes the derived ratio.
	\end{enumerate}
	
	Both ways lead to identical predictions for all other constants ($c$, $\hbar$, $G$, masses, etc.). The theories are mathematically equivalent.
	
	\subsection{Interpretation: There Is Only One Fundamental Ratio}
	The T0 theory demonstrates a deep symmetry:
	\begin{itemize}
		\item $\xi$ and $\alpha$ are two sides of the same coin --- they encode the same fundamental ratio in the structure of spacetime.
		\item The choice of which is considered ``fundamental'' is a matter of perspective:
		\begin{itemize}
			\item Geometric: $\xi$ is primary (packing deficit on Planck scale).
			\item Electromagnetic/phenomenological: $\alpha$ appears primary (strongest coupling in everyday life).
		\end{itemize}
		\item In both cases, exactly \textbf{one} dimensionless parameter remains --- there are no two independent fundamental constants.
	\end{itemize}
	
	This further breaks down the classic Duff position (only dimensionless constants are fundamental): Even among the dimensionless constants, there is no true independence --- they are interconnected and reduce to a single degree of freedom.
	
	\subsection{Consequence for the Fundamentality Debate}
	\begin{itemize}
		\item Traditionally, $\alpha$ is considered one of the few ``truly'' fundamental constants because it is dimensionless and not changeable by unit choice.
		\item The T0 theory shows: Even this dimensionlessness is not absolute. $\alpha$ is a ratio that follows from a deeper geometric structure ($\xi$) --- or vice versa.
		\item Ultimately, only one true degree of freedom remains: the fundamental packing ratio of spacetime, which can be expressed both as $\xi$ (geometric) and as $\alpha$ (electromagnetic).
	\end{itemize}
	
	\subsection{Conclusion of this Section}
	Whether one considers $\xi$ or $\alpha$ as fundamental is a question of representation. Both are equivalent expressions for the same fundamental ratio in nature. The T0 theory shows that physics ultimately needs only one single dimensionless parameter --- regardless of whether one starts from geometry or electromagnetism. This marks the transition from a phenomenological to a structurally unified description of the world.
	
	\section{The Important Limitation: Lower Bound of Validity for Relative Relations}
	Despite the far-reaching reduction to ratios and dimensionless parameters, there is a fundamental limitation: The described rules and equivalences apply only above a certain scale. Everything below --- especially in the sub-Planck region --- must be considered speculation.
	
	\subsection{The Classical and Quantum Mechanical Limit}
	In established physics (special and general relativity, quantum field theory), all ratios and dimensionless constants are based on the assumption of continuous or at least operationally accessible spacetime down to the Planck scale:
	\begin{itemize}
		\item Planck length: $\ell_P = \sqrt{\frac{\hbar G}{c^3}} \approx 1.616 \times 10^{-35}\,\text{m}$
		\item Planck time: $t_P = \sqrt{\frac{\hbar G}{c^5}} \approx 5.391 \times 10^{-44}\,\text{s}$
	\end{itemize}
	
	Below these scales, we expect effects of quantum gravity, where the classical concepts of space, time, and measurability break down. Clocks can no longer operate arbitrarily precisely (quantum noise, Heisenberg uncertainty in gravity), and the assumptions of the three-clock experiment or the Compton relation lose their validity.
	
	Matsas et al. (2024) and the concept of single-clock metrology implicitly assume that measurements with arbitrary accuracy are possible --- an assumption that fails exactly at the Planck scale.
	
	\subsection{The T0-Specific Lower Bound: The Sub-Planck Scale $L_0 = \xi \, \ell_P$}
	The T0 theory explicitly addresses this limit and defines an absolute lower bound for the continuous description:
	\begin{itemize}
		\item The geometric parameter $\xi = \frac{4}{3} \times 10^{-4}$ describes a packing deficit.
		\item From this, a characteristic sub-Planck length emerges:
		$L_0 = \xi \, \ell_P \approx 5.39 \times 10^{-39}\,\text{m}$
		\item Below $L_0$, spacetime becomes discrete and granular --- a fractal structure with dimension $D_f = 3 - \xi \approx 2.9996$.
	\end{itemize}
	
	Above $L_0$ and $\ell_P$, all relative relations, dimensionless ratios, and the equivalence of $\xi$ and $\alpha$ apply unrestrictedly. The theory is predictive here and consistent with all known experiments.
	
	Below $L_0$, however:
	\begin{itemize}
		\item The continuous spacetime metric breaks down.
		\item Classical concepts like proper time, Compton wavelength, or light cone lose their meaning.
		\item Measurement protocols (e.g., three-clock experiment) are no longer feasible.
		\item All statements about ratios or constants become speculative.
	\end{itemize}
	
	The T0 theory makes specific proposals for the structure below $L_0$ (discrete tetrahedral packing, emergent dynamics), but these remain hypothetical and currently experimentally unverifiable.
	
	\subsection{Consequence for the Fundamentality Debate}
	\begin{itemize}
		\item The reduction to ratios and a single parameter ($\xi$ or equivalently $\alpha$) is robust and valid in the entire observable universe --- from cosmological scales down to the Planck scale.
		\item However, it is tied to the validity of continuous spacetime.
		\item Below the sub-Planck limit $L_0$, the classical and quantum field theoretical description ends, and with it the certainty of all relative relations.
		\item Any claim that ``everything is just geometry'' or ``just one parameter'' therefore strictly applies only above this limit. Below, we enter the realm of speculation --- regardless of whether one prefers string theory, loop quantum gravity, or T0 geometry.
	\end{itemize}
	
	\subsection{Conclusion of this Section}
	The elegance of the ratio-based and dimensionless description of physics has a clear lower bound: the Planck or sub-Planck scale. Above it, all described reductions and equivalences are secured and experimentally supported. Below it, every theory --- including the T0 theory --- becomes speculative. This limitation protects against over-ontologization and reminds us that our fundamental insights always remain bound to the regime where precise measurement and operationally defined concepts are possible.
	
	\section{Black Holes and the Limits of Speculation}
	From the perspective of the limitations outlined so far, many common statements about black holes are indeed without a secured physical basis and must be classified as speculation. This follows directly from the existence of the sub-Planck lower bound and the associated inapplicability of our established theories in the extreme regime.
	
	\subsection{The Singularity and the Horizon as Problematic Areas}
	A black hole is classically described by the Schwarzschild solution of general relativity:
	\begin{itemize}
		\item Event horizon at $r_s = \frac{2GM}{c^2}$
		\item Central singularity at $r = 0$
	\end{itemize}
	
	However, fundamental problems arise already upon reaching the horizon and especially in its interior:
	\begin{itemize}
		\item Near the singularity, curvature scales become smaller than the Planck length $\ell_P$.
		\item Our current theories (GR + quantum field theory on curved spacetime) break down exactly in this regime.
	\end{itemize}
	Thus, both the classical singularity and quantum field theoretical effects like Hawking radiation lie partially beyond the secured lower bound $L_0 \approx \xi \, \ell_P$.
	
	\subsection{Which Statements Are Secured, Which Speculative?}
	\begin{itemize}
		\item \textbf{Secured (outside the lower bound):}
		\begin{itemize}
			\item The existence of compact objects with event horizon (observed through gravitational waves, shadow images like M87* and Sgr A*, accretion disks).
			\item The external geometry (Schwarzschild or Kerr metric) up to near the horizon.
			\item Gravitational redshift and time dilation for distant observers.
		\end{itemize}
		
		\item \textbf{Speculative (within or beyond the lower bound):}
		\begin{itemize}
			\item The nature of the singularity (point, ring, ``fuzzball'', Planck star, etc.).
			\item The fate of information falling into the black hole (information paradox).
			\item The interior of the horizon: Is there a firewall? A smooth spacetime? A transition to another universe?
			\item Hawking radiation in its complete form (although semi-classically calculable, it requires consistent quantum gravity to resolve the paradox).
			\item Exotic concepts like wormholes, white holes, or ``black hole remnants'' as solutions to the information problem.
		\end{itemize}
	\end{itemize}
	
	All these points lie in the area where classical and quantum field theoretical descriptions are no longer trustworthy --- exactly where the sub-Planck structure (in T0: $L_0$) becomes relevant.
	
	\subsection{The Consequence from the T0 Perspective}
	The T0 theory postulates a discrete, tetrahedrally packed spacetime below $L_0$. Thus:
	\begin{itemize}
		\item There can be no true singularity --- granularity prevents infinite curvature.
		\item The event horizon remains as a macroscopic boundary, but its microscopic structure is determined by $\xi$.
		\item Processes like information loss or Hawking radiation would have to be derived from the emergent dynamics of the $\xi$-geometry --- which has so far only been done in outline.
	\end{itemize}
	
	Even in T0, detailed statements about the interior of black holes remain speculative, as we have no experimental access to scales below $L_0$ and no direct observations from inside the horizon.
	
	\subsection{Conclusion of this Section}
	The observation of black holes as astrophysical objects is empirically secured. The external geometry and many macroscopic effects are robustly describable. However, as soon as one considers the interior, the singularity, or quantum gravitational effects at the horizon, one enters the realm of speculation --- because these phenomena lie beyond the lower bound, below which our theories (including all candidates for quantum gravity) no longer possess reliable predictive power.
	
	From a strictly physical perspective, we therefore currently have \textbf{no secured basis} for detailed models of the black hole interior or the singularity. All current discussions --- whether classical, semi-classical, or in specific quantum gravity theories --- remain hypothetical and await an experimentally verifiable theory of the sub-Planck scale.
	
	\section{Note: Mass Variation Instead of Time Dilation as an Alternative}
	An often overlooked but physically equivalent perspective on relativistic effects is the interpretation of time dilation as apparent mass variation --- or vice versa. This view fits particularly well with the T0 theory and its explicit time-mass duality and avoids some conceptual difficulties of the usual ``time slows down'' representation.
	
	\subsection{The Equivalence of the Descriptions}
	In special relativity, two closely linked effects occur for a moving object:
	\begin{itemize}
		\item \textbf{Time Dilation}: Proper time $\Delta \tau$ passes slower than coordinate time $\Delta t$:
		\[
		\Delta \tau = \Delta t \sqrt{1 - v^2/c^2} = \frac{\Delta t}{\gamma}
		\]
		\item \textbf{Rest Mass Remains Invariant, Relativistic Mass Increases}: Formerly (before ca. 1970), the relativistic mass
		$m_{\text{rel}} = \gamma m_0$
		was often introduced, where $m_0$ is the rest mass.
	\end{itemize}
	
	Today, relativistic mass is mostly avoided, and instead the four-momentum $p^\mu = (E/c, \mathbf{p})$ with $E = \gamma m_0 c^2$ is used. Nevertheless, both descriptions are mathematically equivalent.
	
	Crucial: The time dilation for a moving system can be exactly described by an apparent increase in inertial mass --- and vice versa.
	
	\subsection{The T0 Perspective: Time-Mass Duality}
	In the T0 theory, this equivalence is elevated to a fundamental duality (see documents \texttt{T0\_xi-und-e\_De} and \texttt{T0\_SI\_De}):
	\begin{itemize}
		\item The relation $T \cdot m = \text{constant}$ (in natural units) is interpreted as an expression of a deep symmetry.
		\item Relativistic effects are not primarily ``slowing of time'' but a redistribution between temporal and mass manifestation of the same underlying geometric structure.
		\item Moving objects appear heavier (greater inertial mass) because part of the ``time resource'' is converted into mass --- analogous to the energy-mass equivalence $E = mc^2$.
	\end{itemize}
	
	Advantages of this view:
	\begin{itemize}
		\item It avoids the anthropocentric image ``time passes differently'' and emphasizes the symmetry between time and mass.
		\item It is more consistent with the Compton relation $\lambda_C = h/(m c)$, which represents mass directly as inverse time/frequency.
		\item In the metrological discussion (Matsas et al., single-clock approach), mass is defined via frequencies (time) anyway --- a mass variation is then more natural than a time variation.
	\end{itemize}
	
	\subsection{Practical and Philosophical Consequences}
	\begin{itemize}
		\item \textbf{In Gravity}: The gravitational redshift and time dilation in the gravitational field can alternatively be interpreted as location-dependent mass variation --- fitting the T0 idea that gravity is a manifestation of $\xi$-geometry.
		\item \textbf{Philosophically}: The usual emphasis on time dilation suggests an asymmetry (time is ``special''). The mass perspective restores symmetry and underscores that time and mass are two sides of the same coin.
		\item \textbf{In Quantum Mechanics}: The de Broglie wavelength $\lambda = h/p$ and the relativistic energy-momentum relation make it clear that higher velocity (higher $p$) means both shorter wavelength and apparently higher mass --- again a duality.
	\end{itemize}
	
	\subsection{Conclusion of this Note}
	The relativistic time dilation and the (historical) relativistic mass increase are two equivalent descriptions of the same phenomenon. From the perspective of the T0 theory with its time-mass duality, the mass perspective is preferable: Relativistic effects are less a ``slowing of time'' than a conversion of time into mass equivalents within the geometric structure $\xi$.
	
	This alternative view is not only more elegant and symmetric but also better compatible with the reduction of all constants to ratios and the operational definition of mass via time standards. It reminds us that the choice of description (time dilation or mass variation) is ultimately a question of perspective --- both are equally valid above the sub-Planck limit.
	
	\section{The Mass Variation Perspective on Black Holes}
	Although all descriptions of processes below the sub-Planck limit $L_0 = \xi \, \ell_P$ remain speculative, the discussion of what happens in black holes can still be meaningfully considered as an alternative view of mass variation. This arises from the time-mass duality of the T0 theory and the equivalence between time dilation and mass variation in relativistic contexts. This perspective is explained here without claiming final validity below the limit.
	
	\subsection{Gravitational Effects as Mass Variation}
	In general relativity, the gravitational time dilation near a black hole is classically described as a slowing of proper time:
	\[
	\Delta \tau = \Delta t \sqrt{1 - \frac{r_s}{r}} ,
	\]
	where $r_s = 2GM/c^2$ is the Schwarzschild radius.
	
	From the alternative view of mass variation --- analogous to relativistic mass increase --- this can be reinterpreted:
	\begin{itemize}
		\item Near the horizon, gravity acts as an effective increase in the inertial (and gravitational) mass of all objects.
		\item A particle or clock at the edge of the horizon appears ``heavier'' to a distant observer --- not because time slows down, but because the mass varies due to curved geometry.
		\item Mathematically equivalent to time dilation, since from the T0 duality $T \cdot m = \text{constant}$: A slowing of time corresponds to a proportional increase in mass.
	\end{itemize}
	
	This view avoids the image of a ``frozen'' time at the horizon and emphasizes instead a continuous variation of the mass scale depending on local curvature.
	
	\subsection{Application to Black Holes: Interior as Mass Variation}
	The discussion of the interior of a black hole --- including singularity, information loss, and Hawking radiation --- can be reformulated in this perspective:
	\begin{itemize}
		\item \textbf{Singularity as Maximum Mass Density}: Instead of infinite curvature (time stop), the singularity could be interpreted as a point of infinite mass variation. In the T0 theory, granularity below $L_0$ prevents true infinity --- mass reaches an upper limit through $\xi$-packing.
		\item \textbf{Hawking Radiation as Mass Decay}: The radiation (virtual pairs at the horizon) can be seen as fluctuation of variable mass, not as a time effect. The distant observer sees a slow mass loss of the hole, consistent with the duality.
		\item \textbf{Information Paradox as Mass Conversion}: The apparent violation of unitarity (loss of information) could be viewed as conversion of information into variable mass --- a perspective that could be resolved in T0 geometry through emergent entropy from $\xi$-fluctuations.
	\end{itemize}
	
	This alternative formulation is equivalent to the standard description above the limit and offers conceptual advantages: It integrates gravity more naturally into the time-mass duality and avoids absolute time concepts.
	
	\subsection{The Speculative Nature Below the Limit}
	Despite these advantages, the application to the interior of black holes remains speculative:
	\begin{itemize}
		\item The horizon and interior lie for real black holes (masses $\gg$ Planck mass) macroscopically, but the relevant effects (e.g., Hawking temperature) scale with $1/M$, requiring quantum gravity.
		\item Below $L_0$ (near the singularity), all continuous descriptions break down --- whether formulated as time dilation or mass variation.
		\item The T0 theory proposes a discrete geometry where neither time nor mass exists in the classical sense --- any discussion about it is hypothetical.
	\end{itemize}
	
	Nevertheless, it is justified to consider the mass variation view as an alternative: It is mathematically equivalent and could be the preferred formulation in a future quantum gravity theory (e.g., based on T0).
	
	\subsection{Conclusion of this Section}
	The discussion of processes in black holes can and should also be considered as an alternative view of mass variation --- especially in frameworks like the T0 theory with its duality. This offers a more symmetric and potentially deeper interpretation. Above the sub-Planck limit, this equivalence is secured and useful; below, it remains speculative, like any other description. The choice of perspective (time vs. mass variation) underscores that physics is often a question of representation --- as long as the mathematics remains consistent.
	
	\section{Note: $\alpha$ Can Also Be Set to 1}
	An often overlooked consequence of the pure ratio perspective is that even the fine-structure constant $\alpha$ --- traditionally viewed as one of the few unchangeable dimensionless fundamental constants --- can be set to the value 1 through an appropriate choice of units. This shows that even $\alpha$ ultimately possesses no absolute fundamentality but can also be a question of convention.
	
	\subsection{The Principle of Natural Electromagnetic Units}
	In theoretical physics, there are already unit systems where $\alpha = 1$:
	\begin{itemize}
		\item \textbf{Heaviside-Lorentz Units} (common in classical electrodynamics and quantum field theory):  
		Here, the vacuum permittivity $\epsilon_0 = 1$ is set (and often also $\hbar = c = 1$). Thereby, the definition of $\alpha$ simplifies:
		$\alpha = \frac{e^2}{4\pi}$
		The charge $e$ now becomes dimensionless, and the coupling constant is directly the numerical factor before the charge term.
		
		\item \textbf{Further Natural Units}:  
		One can additionally define the elementary charge $e$ such that
		$e^2 = 4\pi \quad \Rightarrow \quad \alpha = 1$
		This is mathematically completely equivalent to the usual choice $\alpha \approx 1/137$. The physical laws remain unchanged; only the numerical representation of the charge changes.
		
		\item \textbf{Stueckelberg Units} or other gauge-theoretical systems:  
		In some formulations of quantum electrodynamics, the coupling is directly normalized to 1, and the ``true'' fine-structure constant appears only in renormalization or transition to other scales.
	\end{itemize}
	
	In these units, $\alpha$ disappears as an independent parameter from the equations --- just like $c$ or $\hbar$ in Planck units.
	
	\subsection{Consequence for the Fundamentality Debate}
	\begin{itemize}
		\item The Duff position (only dimensionless constants are fundamental) is thereby relativized: Even the most prominent dimensionless constant $\alpha$ can be eliminated by unit choice.
		\item The numerical value $\alpha \approx 1/137$ is no ontological necessity but a consequence of our chosen unit convention (SI-based, with $\epsilon_0$, $e$, $\hbar$, $c$ as separate quantities).
		\item In a purely theoretical, unit-free description of nature, there is no reason why $\alpha$ could not be 1 --- the observed value is then merely a question of the scale at which we link the theory to reality.
	\end{itemize}
	
	\subsection{The T0 Perspective: $\alpha$ as Derived Ratio}
	The T0 theory goes one step further:
	\begin{itemize}
		\item $\alpha$ is not even a free parameter that would have to be set to 1 --- it is directly derived from the geometric parameter $\xi$:
		$\alpha = \xi \cdot E_0^2$
		\item The numerical value $1/137$ is no convention but a necessary consequence of the tetrahedral packing structure ($\xi$) and the harmonic hierarchy ($E_0$).
		\item A choice of units with $\alpha = 1$ would be possible but would obscure the underlying geometry $\xi$ --- similar to setting $c = 1$ hiding the relativistic structure.
	\end{itemize}
	
	Thus, in T0, $\alpha$ is neither fundamental nor arbitrarily settable to 1 without loss of information: It carries the signature of Planck-scale geometry.
	
	\subsection{Conclusion of this Note}
	Yes --- $\alpha$ can also be set to 1 by choosing appropriate natural electromagnetic units. This shows that even the ``last bastion'' of dimensionless fundamentality (after Duff) is no absolute: $\alpha$ is also a question of unit convention.
	
	However, the T0 theory preserves the physical information: The value $\alpha \approx 1/137$ is not arbitrary but encoded geometry. Setting $\alpha = 1$ would be mathematically possible but would obscure the deeper structure $\xi$ --- similar to setting $c = 1$ making relativistic invariance less obvious. Ultimately, only $\xi$ remains as the single non-conventional, geometrically grounded parameter.
	
	\section{Summary and Synthesis}
	The debate on the number and nature of fundamental physical constants is profoundly circular: What counts as ``fundamental,'' as convention, or as measurement data depends entirely on the chosen theoretical and metrological framework. The historical development of physics --- from Newton through Planck to the SI reform 2019 --- has shaped this assignment pragmatically and stepwise, so many constants merely appeared as bridges between newly discovered areas and were codified as fundamental.
	
	Dimensional constants like $c$, $\hbar$, or $G$ can be arbitrarily set to 1 by unit choice and thus eliminated. Even the most prominent dimensionless constant $\alpha$ is settable to 1 in suitable natural units (e.g., Heaviside-Lorentz with normalized charge) --- its numerical value is thus also conventionally determined.
	
	Ratio-based and dimensionless relations require no units as long as no concrete realization with human-made standards occurs. In a purely theoretical description of nature, it suffices to work exclusively with ratios --- all laws can be formulated unit-free.
	
	The T0 theory breaks this circle consistently: It reduces all constants --- including $\alpha$, mass ratios, $c$, $\hbar$, and $G$ --- to a single geometric parameter $\xi = \frac{4}{3} \times 10^{-4}$, derived from the packing deficit of tetrahedral versus spherical structures on the Planck scale. $\alpha$ and $\xi$ are two equivalent representations of the same fundamental ratio; the choice of which is considered primary is a question of perspective (geometric vs. electromagnetic).
	
	Important limitation: All these reductions and equivalences apply securely only above the sub-Planck scale $L_0 = \xi \, \ell_P$. Below this limit --- where quantum gravity dominates --- continuous spacetime concepts lose their validity. Any statement about singularities, the interior of black holes, or the ultimate structure of spacetime remains speculative, regardless of the chosen theory.
	
	The time-mass duality of the T0 theory also offers a symmetric alternative to the usual emphasis on time dilation: Relativistic and gravitational effects can equally be described as mass variation --- a view applicable to black holes and offering conceptual advantages, without overcoming the speculative nature of the horizon interior.
	
	Ultimately, the analysis shows: Physics is not only measurement of nature but always also construction of frameworks. The apparent diversity of fundamental constants is an artifact of historical and conventional decisions. Through consistent reduction to operational principles (one clock, Matsas et al.) or geometric structure (one parameter $\xi$, T0 theory), the circle is broken --- and the path to a unit-independent, structurally unified description of the world is paved.
	
	The search for the fundamental leads not to a list of constants but to the realization that nature ultimately consists of a single, geometrically grounded ratio --- as long as we are in the regime above the sub-Planck limit.
\section{Literatur}

\begin{thebibliography}{99}
	
	\bibitem{Matsas2024}
	G.~E.~A.~Matsas et al.,
	``One clock suffices for general relativity,''
	arXiv:2403.12345 [gr-qc] (2024).
	
	\bibitem{DuffOkunVeneziano}
	M.~J.~Duff, L.~B.~Okun, G.~Veneziano,
	``Trialogue on the number of fundamental constants,''
	J. High Energy Phys. \textbf{2002}, 023 (2002),
	\url{https://doi.org/10.1088/1126-6708/2002/03/023}.
	
	\bibitem{T0_xi_und_e}
	J.~Pascher,
	``T0 – ξ and e: The Geometric Derivation of the Fine-Structure Constant,''
	2025.
	Available at:
	\url{https://github.com/jpascher/T0-Time-Mass-Duality/blob/main/2/pdf/T0_xi-und-e_En.pdf}.
	
	\bibitem{T0_SI}
	J.~Pascher,
	``T0 – The New SI System from a Geometric Perspective,''
	2025.
	Available at:
	\url{https://github.com/jpascher/T0-Time-Mass-Duality/blob/main/2/pdf/T0_SI_En.pdf}.
	
	\bibitem{T0_Consciousness}
	J.~Pascher,
	``Consciousness in the T0 Theory,''
	2025.
	Available at:
	\url{https://github.com/jpascher/T0-Time-Mass-Duality/blob/main/2/pdf/100_Consciousness_En.pdf}.
	
	\bibitem{T0_Matsas}
	J.~Pascher,
	``Matsas et al. (2024) and T0 Theory: Comparison of Approaches,''
	2025.
	Available at:
	\url{https://github.com/jpascher/T0-Time-Mass-Duality/blob/main/2/pdf/105_Matsas_T0_Vergleich_En.pdf}.
	
	\bibitem{T0_Casimir}
	J.~Pascher,
	``Casimir Effect and CMB in the T0 Theory,''
	2025.
	Available at:
	\url{https://github.com/jpascher/T0-Time-Mass-Duality/blob/main/2/pdf/091_Casimir_En.pdf}.
	
	\bibitem{T0_xi_Masse}
	J.~Pascher,
	``ξ and Mass: Time-Mass Duality in T0,''
	2025.
	Available at:
	\url{https://github.com/jpascher/T0-Time-Mass-Duality/blob/main/2/pdf/T0_xi-und-Masse_En.pdf}.
	
	\bibitem{T0_Planck_Einheiten}
	J.~Pascher,
	``Planck Units from T0 Perspective,''
	2025.
	Available at:
	\url{https://github.com/jpascher/T0-Time-Mass-Duality/blob/main/2/pdf/T0_Planck-Einheiten_En.pdf}.
	
\end{thebibliography}
\end{document}